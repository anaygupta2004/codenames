/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: do not edit it. Instead, edit the BAML
// files and re-generate this code.
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code
const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> Sonnet35 {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> GeminiPro {\n  provider google-ai\n  options {\n    model \"gemini-1.5-pro\"\n    api_key env.GOOGLE_API_KEY\n  }\n}\n\n\n\nclient<llm> Grok {\n  provider \"openai-generic\"\n  options {\n    base_url \"https://api.x.ai/v1/chat/completions\"\n    api_key env.XAI_API_KEY\n    model grok-2-1212\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "codenames.baml": "class SpymasterClue {\n  word string @description(\"The one-word clue given by the spymaster\")\n  number int @description(\"Number of words related to the clue\")\n  reasoning string @description(\"Explanation for the chosen clue\")\n}\n\nclass GameState {\n  currentTeam \"red\" | \"blue\"\n  words string[]\n  teamWords string[] @description(\"Words belonging to the current team\")\n  opposingWords string[] @description(\"Words belonging to the opposing team\")\n  assassinWord string\n  revealedCards string[]\n}\n\nclass GameAnalysis {\n  message string @alias(\"analysis\")\n  suggestedMoves Guess[] @alias(\"suggested moves\")\n}\n\nenum Risk {\n  High\n  Medium\n  Low\n}\n\nclass MetaDecision {\n  decision Decision\n  reasoning string[]\n}\n\nenum Decision {\n  Continue @description(\"Continue the game\")\n  ContunueWait @description(\"Continue the game, but wait for a consensus\")\n  EndTurn @description(\"End the turn\")\n}\n\nclass Guess {\n  word string\n  reasoning string\n  discussion string\n  risk Risk\n}\n\nclass GuessDiscussion {\n  candidateGuesses Guess[]\n  discussionLog string[]\n  conversationRounds int @description(\"Number of rounds of discussion that have occurred\")\n  participantContributions map<string, int> @description(\"Tracks how many times each participant has contributed\")\n  consensusReached bool @description(\"Whether consensus has been reached among participants\")\n  consensusLevel ConsensusLevel @description(\"Level of consensus among participants\")\n  suggestedAction Decision @description(\"Suggested next action based on current discussion state\")\n}\n\nenum ConsensusLevel {\n  High @description(\"All players strongly agree on the guess\")\n  Medium @description(\"Most players agree on the guess\")\n  Low @description(\"Some players disagree on the guess\")\n}\n\nfunction GenerateClue(state: GameState) -> SpymasterClue {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    You are the Codenames spymaster for the {{ state.currentTeam }} team.\n\n    Your team's words: {{ state.teamWords }}\n    Opposing team's words (avoid): {{ state.opposingWords }}\n    Assassin word (must avoid): {{ state.assassinWord }}\n    Words already revealed: {{ state.revealedCards }}\n\n    Give a strategic one-word clue to help your team find their unrevealed words while avoiding others.\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }} Based on these words, provide a strategic clue and number.\n  \"#\n}\n\nfunction AnalyzeClue(\n  clue: SpymasterClue,\n  state: GameState\n) -> GameAnalysis {\n  client \"anthropic/claude-3-5-sonnet-latest\"\n  prompt #\"\n    You are a Codenames player on the {{ state.currentTeam }} team.\n    \n    The spymaster has given the clue: \"{{ clue.word }}\" ({{ clue.number }})\n\n    Available words: {{ state.words }}\n    Words already revealed: {{ state.revealedCards }}\n\n    Analyze this clue and suggest guesses.\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }} Analyze this clue and make a recommendation.\n  \"#\n}\n\nfunction ValidateGuess(\n  guess: Guess,\n  clue: SpymasterClue,\n  state: GameState,\n  discussion: GuessDiscussion\n) -> GameAnalysis {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    You are validating a potential guess in Codenames.\n\n    Clue given: \"{{ clue.word }}\" ({{ clue.number }})\n    Proposed guess: \"{{ guess.word }}\"\n    \n    Current game state:\n    - Team: {{ state.currentTeam }}\n    - Available words: {{ state.words }}\n    - Revealed cards: {{ state.revealedCards }}\n\n    {{ ctx.output_format }}\n\n    {{ _.role(\"user\") }} Evaluate whether this word is a good guess based on the clue.\n  \"#\n}\n\nfunction FinalizeGuess(\n  state: GameState,\n  discussion: GuessDiscussion\n) -> Guess {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    You are a Codenames player on the {{ state.currentTeam }} team.\n    \n    Based on the discussion below and candidate guesses:\n    - Discussion log: {{ discussion.discussionLog }}\n    - Candidate guesses: {{ discussion.candidateGuesses }}\n    \n    If a consensus has been reached among the players on a specific guess, choose that word and provide your reasoning and risk level.\n    If consensus is not reached, state that no consensus has been achieved. If you are unsure, choose the highest risk guess.\n\n    Engage in a natural conversation with the other players to reach a consensus. Initiate the conversation if needed.\n    \n    {{ ctx.output_format }}\n    \n    {{ _.role(\"user\") }} Provide the final guess if consensus has been reached.\n  \"#\n}\n\nfunction DetermineNextAction(\n  state: GameState,\n  currentClue: SpymasterClue,\n  previousGuesses: Guess[],\n  previousDiscussion: GuessDiscussion\n) -> MetaDecision {\n  client \"openai/gpt-4o\"\n  prompt #\"\n    Based on the current game state:\n    - Clue: \"{{ currentClue.word }}\" ({{ currentClue.number }})\n    - Past guesses: {{ previousGuesses }}\n    - Discussion log: {{ previousDiscussion.discussionLog }}\n        \n    {{ ctx.output_format }}\n    \n    {{ _.role(\"user\") }} Provide the decision with your reasoning.\n  \"#\n}\n",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.77.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}